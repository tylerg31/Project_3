{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_excel(Path(\"./Denver_data.xlsx\"))\n",
    "display(df.head())\n",
    "\n",
    "# Create the features set (X)\n",
    "# The features dataset consists of columns 0 to 67\n",
    "X = df.iloc[:, 160:260]\n",
    "\n",
    "# Scale the data of the features set using the StandardScaler\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# Create a shallow, 1 hidden layer, neural network\n",
    "\n",
    "# Instantiate an instance of the Sequential model\n",
    "nn = Sequential()\n",
    "\n",
    "# Create 1 hidden layer\n",
    "nn.add(Dense(units=8, input_dim=100, activation=\"relu\"))\n",
    "\n",
    "# Create the output layer\n",
    "nn.add(Dense(units=100, activation=\"linear\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and mse.\n",
    "nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "# Fit the model\n",
    "model_1 = nn.fit(X, X, validation_split=0.5, epochs=50, verbose=0)\n",
    "\n",
    "# Create a deep neural network with 2 hidden layers\n",
    "\n",
    "# Instantiate an instance of the Sequential model\n",
    "dnn = Sequential()\n",
    "\n",
    "# Create the first hidden layer\n",
    "dnn.add(Dense(units=8, input_dim=100, activation=\"relu\"))\n",
    "\n",
    "# Create the second hidden layer\n",
    "dnn.add(Dense(units=8, activation=\"relu\"))\n",
    "\n",
    "# Create the Output layer\n",
    "dnn.add(Dense(units=100, activation=\"linear\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and mse.\n",
    "dnn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "model_2 = dnn.fit(X, X, validation_split=0.5, epochs=50, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m preds_1 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mpredict(X)\n\u001b[0;32m      2\u001b[0m preds_2 \u001b[39m=\u001b[39m dnn\u001b[39m.\u001b[39mpredict(X)\n\u001b[0;32m      3\u001b[0m \u001b[39m# assume x and pred_x are numpy arrays or lists of the same length\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "preds_1 = nn.predict(X)\n",
    "preds_2 = dnn.predict(X)\n",
    "# assume x and pred_x are numpy arrays or lists of the same length\n",
    "plt.plot(X, label='x', color='purple')\n",
    "plt.plot(preds_2, label='pred_x', color='yellow')\n",
    "plt.plot(preds_1, label='pred_x', color='blue')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot predicted vs actual"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stockprice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
